{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils.data_utils import *\n",
    "from utils.motion_utils import *\n",
    "from utils.evaluate import *\n",
    "import re\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFieldStrength(h_file):\n",
    "    ismhd = h_file[\"ismrmrd_header\"][()]\n",
    "    match = re.findall(\n",
    "        r\"<systemFieldStrength_T>\\d\\.\\d*</systemFieldStrength_T>\", str(ismhd)\n",
    "    )[0]\n",
    "    match = match.replace(\"<systemFieldStrength_T>\", \"\")\n",
    "    match = match.replace(\"</systemFieldStrength_T>\", \"\")\n",
    "    return 1.5 if float(match) < 2.0 else 3.0\n",
    "\n",
    "\n",
    "def getAcquisitionType(h_file):\n",
    "    return \"PD\" if h_file.attrs[\"acquisition\"] == \"CORPD_FBK\" else \"PDFS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_split(PATH=\"Dataset/FastMRI/t2\"):\n",
    "\n",
    "    print(\"Crating Train Set\")\n",
    "    Train_PATH = os.path.join(PATH, \"train/\")\n",
    "    hf_map = {}\n",
    "    for fname in tqdm(os.listdir(Train_PATH)):\n",
    "        with h5py.File(os.path.join(Train_PATH, fname)) as hf:\n",
    "            hf_map[fname] = (getFieldStrength(hf), getAcquisitionType(hf))\n",
    "\n",
    "    PD_1T = [f for f, v in hf_map.items() if v == (1.5, \"PD\")]\n",
    "    PD_3T = [f for f, v in hf_map.items() if v == (3.0, \"PD\")]\n",
    "    PDFS_1T = [f for f, v in hf_map.items() if v == (1.5, \"PDFS\")]\n",
    "    PDFS_3T = [f for f, v in hf_map.items() if v == (3.0, \"PDFS\")]\n",
    "\n",
    "    train_list = np.concatenate([PDFS_1T, PDFS_3T])\n",
    "\n",
    "    train_list = np.random.choice(train_list, 200, replace=False)\n",
    "\n",
    "    train_path = \"../Dataset/Brain/t2/train_files/\"\n",
    "    if not os.path.exists(train_path):\n",
    "        os.makedirs(train_path)\n",
    "    with h5py.File(train_path + \"_train_data.h5\", \"w\") as f:\n",
    "        for fname in tqdm(train_list):\n",
    "            hf = h5py.File(os.path.join(Train_PATH, fname))\n",
    "            f.create_dataset(fname, data=hf[\"kspace\"][:])\n",
    "            hf.close()\n",
    "\n",
    "    # validation set\n",
    "    print(\"Creating Validation set\")\n",
    "    VAL_PATH = os.path.join(PATH, \"val/\")\n",
    "    hf_map = {}\n",
    "\n",
    "    for fname in tqdm(os.listdir(VAL_PATH)):\n",
    "        with h5py.File(os.path.join(VAL_PATH, fname)) as hf:\n",
    "            hf_map[fname] = (getFieldStrength(hf), getAcquisitionType(hf))\n",
    "\n",
    "    PD_1T = [f for f, v in hf_map.items() if v == (1.5, \"PD\")]\n",
    "    PD_3T = [f for f, v in hf_map.items() if v == (3.0, \"PD\")]\n",
    "    PDFS_1T = [f for f, v in hf_map.items() if v == (1.5, \"PDFS\")]\n",
    "    PDFS_3T = [f for f, v in hf_map.items() if v == (3.0, \"PDFS\")]\n",
    "\n",
    "    val_list = np.concatenate([PDFS_1T, PDFS_3T])\n",
    "\n",
    "    val_list = np.random.choice(val_list, 50, replace=False)\n",
    "\n",
    "    val_path = \"../Dataset/Brain/t2/val_files/\"\n",
    "    if not os.path.exists(val_path):\n",
    "        os.makedirs(val_path)\n",
    "\n",
    "    with h5py.File(val_path + \"_val_data.h5\", \"w\") as f:\n",
    "        for fname in tqdm(val_list):\n",
    "            hf = h5py.File(os.path.join(VAL_PATH, fname))\n",
    "            f.create_dataset(fname, data=hf[\"kspace\"][:])\n",
    "            hf.close()\n",
    "\n",
    "    print(\"Crating Test Set\")\n",
    "    Test_PATH = os.path.join(PATH, \"test/\")\n",
    "    hf_map = {}\n",
    "\n",
    "    for fname in tqdm(os.listdir(Test_PATH)):\n",
    "        with h5py.File(os.path.join(Test_PATH, fname)) as hf:\n",
    "            hf_map[fname] = (getFieldStrength(hf), getAcquisitionType(hf))\n",
    "\n",
    "    PD_1T = [f for f, v in hf_map.items() if v == (1.5, \"PD\")]\n",
    "    PD_3T = [f for f, v in hf_map.items() if v == (3.0, \"PD\")]\n",
    "    PDFS_1T = [f for f, v in hf_map.items() if v == (1.5, \"PDFS\")]\n",
    "    PDFS_3T = [f for f, v in hf_map.items() if v == (3.0, \"PDFS\")]\n",
    "\n",
    "    test_list = np.concatenate([PDFS_1T, PDFS_3T])\n",
    "\n",
    "    test_list = np.random.choice(test_list, 51, replace=False)\n",
    "\n",
    "    test_path = \"../Dataset/Brain/t2/test_files/\"\n",
    "    if not os.path.exists(test_path):\n",
    "        os.makedirs(test_path)\n",
    "\n",
    "    with h5py.File(test_path + \"_test_data.h5\", \"w\") as f:\n",
    "        for fname in tqdm(test_list):\n",
    "            hf = h5py.File(os.path.join(Test_PATH, fname))\n",
    "            f.create_dataset(fname, data=hf[\"kspace\"][:])\n",
    "            hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(path=\"Dataset/Brain/t2/train_files/_train_data.h5\"):\n",
    "\n",
    "    data_file = h5py.File(path)\n",
    "\n",
    "    kspaces = []\n",
    "\n",
    "    for file_name in tqdm(sorted(list(data_file.keys()))):\n",
    "        ks = torch.from_numpy(data_file[file_name][()][1])\n",
    "\n",
    "        kspace, _ = prepare_data(ks)\n",
    "\n",
    "        # if the shapes are not 320x320, then skip the sample\n",
    "        if kspace.shape != torch.Size([320, 320]):\n",
    "            print(kspace.shape)\n",
    "            print(\"Skipping sample with shape: \", kspace.shape)\n",
    "            continue\n",
    "\n",
    "        kspaces.append(kspace)\n",
    "\n",
    "    # create a dictionary for all lists that are tansformed to tensors\n",
    "    # make tensors from the the lists from the for loop\n",
    "    kspaces = torch.stack(kspaces).squeeze()\n",
    "\n",
    "    data = {\"kspace\": kspaces}\n",
    "\n",
    "    # save the dict as torch file\n",
    "    torch.save(data, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 25/51 [00:27<00:14,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 24])\n",
      "Skipping sample with shape:  torch.Size([320, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:42<00:00,  1.20it/s]\n",
      " 49%|████▉     | 25/51 [00:15<00:11,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 24])\n",
      "Skipping sample with shape:  torch.Size([320, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:27<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def motion_test_data(path):\n",
    "    test_data_file = h5py.File(path)\n",
    "    \"../Dataset/Brain/t2/test_files/_test_data.h5\"\n",
    "    scenarios = [\"light\", \"heavy\"]\n",
    "    movements = [np.arange(6, 10), np.arange(16, 20)]\n",
    "    metrics_all = defaultdict(list)\n",
    "    for scenario, movement in zip(scenarios, movements):\n",
    "        scenario_path = path.split(\".h5\")[0] + \"_\" + scenario + \".pth\"\n",
    "        metrics = []\n",
    "        kspaces_motion = []\n",
    "        images_rss = []\n",
    "        rotations = []\n",
    "        translations = []\n",
    "        masks = []\n",
    "        for file_name in tqdm(sorted(list(test_data_file.keys()))):\n",
    "            ks = torch.from_numpy(test_data_file[file_name][()][0])\n",
    "\n",
    "            kspace, image_rss = prepare_data(ks)\n",
    "            num_movements = np.random.choice(movement, 1, replace=True)[0]\n",
    "            # if the shapes are not 320x320, then skip the sample\n",
    "            if kspace.shape != torch.Size([320, 320]):\n",
    "                print(kspace.shape)\n",
    "                print(\"Skipping sample with shape: \", kspace.shape)\n",
    "                continue\n",
    "\n",
    "            kspace_motion, mask, rotation, translation = motion_simulation2D(\n",
    "                IFFT(kspace), num_movements\n",
    "            )\n",
    "\n",
    "            kspaces_motion.append(kspace_motion)\n",
    "            images_rss.append(image_rss)\n",
    "            rotations.append(rotation)\n",
    "            translations.append(translation)\n",
    "            masks.append(mask)\n",
    "\n",
    "            H, W = kspace_motion.shape\n",
    "\n",
    "            crop = [int(H / 4), int(W / 4)]\n",
    "            image_gt_crop = image_rss.abs()[crop[0] : -crop[0], crop[1] : -crop[1]]\n",
    "            motion_corrupted_crop = IFFT(kspace_motion).abs()[\n",
    "                crop[0] : -crop[0], crop[1] : -crop[1]\n",
    "            ]\n",
    "\n",
    "            psnr, ssim, haar_psi, rmse = calmetric2D(\n",
    "                motion_corrupted_crop[None, None], image_gt_crop[None, None]\n",
    "            )\n",
    "\n",
    "            # make a dictionary with the metrics\n",
    "            metrics.append(\n",
    "                {\"ssim\": ssim, \"psnr\": psnr, \"haar_psi\": haar_psi, \"rmse\": rmse}\n",
    "            )\n",
    "\n",
    "        # create a dictionary for all lists that are tansformed to tensors\n",
    "        # make tensors from the the lists from the for loop\n",
    "        kspace_motion = torch.stack(kspaces_motion).squeeze()\n",
    "        image_rss = torch.stack(images_rss).squeeze()\n",
    "        rotation = rotations\n",
    "        translation = translations\n",
    "        mask = torch.stack(masks).squeeze()\n",
    "\n",
    "        data = {\n",
    "            \"kspace_motion\": kspace_motion,\n",
    "            \"image_rss\": image_rss,\n",
    "            \"rotation\": rotation,\n",
    "            \"translation\": translation,\n",
    "            \"mask\": mask,\n",
    "            \"metrics\": metrics,\n",
    "        }\n",
    "\n",
    "        # save the dict as torch file\n",
    "        torch.save(data, scenario_path)\n",
    "        # append the metrics to the metrics_all list\n",
    "        metrics_all[scenario] = metrics\n",
    "\n",
    "    return data, metrics_all\n",
    "\n",
    "\n",
    "scenarios = [\"light\", \"heavy\"]\n",
    "data, metrics_all = motion_test_data(\"../Dataset/Brain/t2/test_files/_test_data.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
